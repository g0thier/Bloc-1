{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good to know : create a bucket \n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-creating-buckets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload on S3\n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did he encounter a problem ? : None\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# gitignore file security AWS password access\n",
    "# rootkey.csv create in webconsole AWS -> MYNAME -> Info. Id. Secu. -> IAM -> Access Key \n",
    "rootkey = pd.read_csv('src/rootkey.csv',header=None, sep=\"=\").T\n",
    "rootkey.columns = rootkey.iloc[0]\n",
    "rootkey = rootkey.drop([0])\n",
    "\n",
    "# Sensitive informations Account\n",
    "AWSAccessKeyId = rootkey['AWSAccessKeyId'].iloc[0]\n",
    "AWSSecretKey = rootkey['AWSSecretKey'].iloc[0]\n",
    "\n",
    "# Open session \n",
    "session = boto3.Session(aws_access_key_id=AWSAccessKeyId, \n",
    "                        aws_secret_access_key=AWSSecretKey)\n",
    "\n",
    "# Run session\n",
    "s3 = session.resource(\"s3\")\n",
    "\n",
    "# Upload file \n",
    "bucket_name = 'compartiment-bucket-s3-jedha-rg'\n",
    "path = 'src/s3_booking_weather_dataset.csv'\n",
    "name = 'booking_weather_dataset.csv'\n",
    "result = s3.Bucket(bucket_name).upload_file(path,name)\n",
    "\n",
    "# It's OK ?\n",
    "print(f'Did he encounter a problem ? : {result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
